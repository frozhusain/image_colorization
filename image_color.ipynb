{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_color.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-hCALF4xCN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# DIRECTORY INFORMATION\n",
        "DATASET = \"Dogs\"\n",
        "ROOT_DIR = os.path.abspath('/content/mod')\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'DATASET/'+DATASET+'/')\n",
        "OUT_DIR = os.path.join(ROOT_DIR, 'RESULT/'+DATASET+'/')\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, 'MODEL/')\n",
        "LOG_DIR = os.path.join(ROOT_DIR, 'LOGS/'+DATASET+'/')\n",
        "\n",
        "TRAIN_DIR = \"/content/train\"    # Train dataset path\n",
        "TEST_DIR = \"/content/sky/test_grey\"    #Test dataset path \n",
        "\n",
        "# DATA INFORMATION\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# RANDOM NUMBER GENERATOR INFORMATION\n",
        "SEED = 128\n",
        "\n",
        "# TRAINING INFORMATION\n",
        "USE_PRETRAINED = False\n",
        "PRETRAINED = \"model1_1.ckpt\"\n",
        "NUM_EPOCHS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYgJzTcwxQSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "class DATA():\n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dir_path = os.path.join(DATA_DIR, dirname)\n",
        "        self.filelist = os.listdir(self.dir_path)\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.size = len(self.filelist)\n",
        "        self.data_index = 0\n",
        "\n",
        "    def read_img(self, filename):\n",
        "        img = cv2.imread(filename, 3)\n",
        "        height, width, channels = img.shape\n",
        "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
        "        return np.reshape(labimg[:,:,0], (IMAGE_SIZE,IMAGE_SIZE, 1)), labimg[:, :, 1:]\n",
        "\n",
        "    def generate_batch(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        filelist = []\n",
        "        for i in range(self.batch_size):\n",
        "            filename = os.path.join(DATA_DIR, self.dir_path, self.filelist[self.data_index])\n",
        "            filelist.append(self.filelist[self.data_index])\n",
        "            greyimg, colorimg = self.read_img(filename)\n",
        "            batch.append(greyimg)\n",
        "            labels.append(colorimg)\n",
        "            self.data_index = (self.data_index + 1) % self.size\n",
        "        batch = np.asarray(batch)/255\n",
        "        labels = np.asarray(labels)/255\n",
        "        return batch, labels, filelist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQZdhyXGxYDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow.compat.v1 as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "def deprocess(imgs):\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "\n",
        "def reconstruct(batchX, predictedY, filelist):\n",
        "    for i in range(BATCH_SIZE):\n",
        "        result = np.concatenate((batchX[i], predictedY[i]), axis=2)\n",
        "        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "        save_path = os.path.join(OUT_DIR, filelist[i][:-4] + \"reconstructed.jpg\")\n",
        "        cv2.imwrite(save_path, result)\n",
        "        cv2_imshow(result)\n",
        "\n",
        "\n",
        "class MODEL():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.inputs = tf.placeholder(shape=[BATCH_SIZE, IMAGE_SIZE,IMAGE_SIZE, 1], dtype=tf.float32)\n",
        "        self.labels = tf.placeholder(shape=[BATCH_SIZE, IMAGE_SIZE,IMAGE_SIZE, 2], dtype=tf.float32)\n",
        "        self.loss = None\n",
        "        self.output = None\n",
        "\n",
        "    def build(self):\n",
        "        input_data = self.inputs\n",
        "        low_level_conv1 = Convolution_Layer(shape=[3, 3, 1, 64], stddev=0.1, value=0.1)\n",
        "        h = low_level_conv1.feed_forward(input_data=input_data, stride=[1, 2, 2, 1])\n",
        "\n",
        "        low_level_conv2 =Convolution_Layer(shape=[3, 3, 64, 128], stddev=0.1, value=0.1)\n",
        "        h = low_level_conv2.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        low_level_conv3 =Convolution_Layer(shape=[3, 3, 128, 128], stddev=0.1, value=0.1)\n",
        "        h = low_level_conv3.feed_forward(input_data=h, stride=[1, 2, 2, 1])\n",
        "\n",
        "        low_level_conv4 = Convolution_Layer(shape=[3, 3, 128, 256], stddev=0.1, value=0.1)\n",
        "        h = low_level_conv4.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        low_level_conv5 =Convolution_Layer(shape=[3, 3, 256, 256], stddev=0.1, value=0.1)\n",
        "        h = low_level_conv5.feed_forward(input_data=h, stride=[1, 2, 2, 1])\n",
        "\n",
        "        low_level_conv6 = Convolution_Layer(shape=[3, 3, 256, 512], stddev=0.1, value=0.1)\n",
        "        h = low_level_conv6.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        mid_level_conv1 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
        "        h1 = mid_level_conv1.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        mid_level_conv2 =Convolution_Layer(shape=[3, 3, 512, 256], stddev=0.1, value=0.1)\n",
        "        h1 = mid_level_conv2.feed_forward(input_data=h1, stride=[1, 1, 1, 1])\n",
        "\n",
        "        global_level_conv1 =Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
        "        h2 = global_level_conv1.feed_forward(input_data=h, stride=[1, 2, 2, 1])\n",
        "\n",
        "        global_level_conv2 =Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
        "        h2 = global_level_conv2.feed_forward(input_data=h2, stride=[1, 1, 1, 1])\n",
        "\n",
        "        global_level_conv3 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
        "        h2 = global_level_conv3.feed_forward(input_data=h2, stride=[1, 2, 2, 1])\n",
        "\n",
        "        global_level_conv4 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
        "        h2 = global_level_conv4.feed_forward(input_data=h2, stride=[1, 1, 1, 1])\n",
        "\n",
        "        h2_flat = tf.reshape(h2, [BATCH_SIZE, -1])\n",
        "        dim = h2_flat.get_shape()[1].value\n",
        "        global_level_FC1 =FullyConnected_Layer(shape=[dim, 1024], stddev=0.04, value=0.1)\n",
        "        h2 = global_level_FC1.feed_forward(input_data=h2_flat)\n",
        "\n",
        "        global_level_FC2 = FullyConnected_Layer(shape=[1024, 512], stddev=0.04, value=0.1)\n",
        "        h2 = global_level_FC2.feed_forward(input_data=h2)\n",
        "\n",
        "        global_level_FC3 =FullyConnected_Layer(shape=[512, 256], stddev=0.04, value=0.1)\n",
        "        h2 = global_level_FC3.feed_forward(input_data=h2)\n",
        "\n",
        "        fusion_layer =Fusion_Layer(shape=[1, 1, 512, 256], stddev=0.1, value=0.1)\n",
        "        h = fusion_layer.feed_forward(h1, h2, stride=[1, 1, 1, 1])\n",
        "\n",
        "        colorization_level_conv1 = Convolution_Layer(shape=[3, 3, 256, 128], stddev=0.1, value=0.1)\n",
        "        h = colorization_level_conv1.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        h = tf.image.resize_images(h, [56, 56], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "        colorization_level_conv2 = Convolution_Layer(shape=[3, 3, 128, 64], stddev=0.1, value=0.1)\n",
        "        h = colorization_level_conv2.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        colorization_level_conv3 = Convolution_Layer(shape=[3, 3, 64, 64], stddev=0.1, value=0.1)\n",
        "        h = colorization_level_conv3.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        h = tf.image.resize_images(h, [112, 112], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "        colorization_level_conv4 = Convolution_Layer(shape=[3, 3, 64, 32], stddev=0.1, value=0.1)\n",
        "        h = colorization_level_conv4.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        output_layer = Output_Layer(shape=[3, 3, 32, 2], stddev=0.1, value=0.1)\n",
        "        logits = output_layer.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
        "\n",
        "        self.output = tf.image.resize_images(logits, [224, 224], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "        self.loss = tf.reduce_mean(tf.squared_difference(self.labels, self.output))\n",
        "\n",
        "    def train(self, data):\n",
        "        optimizer = tf.train.AdamOptimizer(1e-4).minimize(self.loss)\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(tf.global_variables_initializer())\n",
        "            print('All variables Initialized')\n",
        "            if USE_PRETRAINED:\n",
        "                saver.restore(session, os.path.join(MODEL_DIR,PRETRAINED))\n",
        "                print('Pretrained weights loaded')\n",
        "            for epoch in range(NUM_EPOCHS):\n",
        "                avg_cost = 0\n",
        "                for batch in range(int(data.size/BATCH_SIZE)):\n",
        "                    batchX, batchY, _ = data.generate_batch()\n",
        "                    feed_dict = {self.inputs: batchX, self.labels: batchY}\n",
        "                    _, loss_val = session.run([optimizer, self.loss], feed_dict=feed_dict)\n",
        "                    print(\"batch:\", batch, \" loss: \", loss_val)\n",
        "                    avg_cost += loss_val / int(data.size/BATCH_SIZE)\n",
        "                print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.5f}\".format(avg_cost))\n",
        "              #  log.write(\"Epoch: \" + str(epoch + 1) + \" Average Cost: \" + str(avg_cost) + \"\\n\")\n",
        "\n",
        "            save_path = saver.save(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
        "            print(\"Model saved in path: %s\" % save_path)\n",
        "            #log.write(\"Model saved in path: \" + save_path + \"\\n\")\n",
        "\n",
        "    def test(self, data):\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            saver.restore(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
        "            avg_cost = 0\n",
        "            total_batch = int(data.size/BATCH_SIZE)\n",
        "            for _ in range(total_batch):\n",
        "                batchX, batchY, filelist = data.generate_batch()\n",
        "                feed_dict = {self.inputs: batchX, self.labels: batchY}\n",
        "                predY, loss = session.run([self.output, self.loss], feed_dict=feed_dict)\n",
        "                reconstruct(deprocess(batchX), deprocess(predY), filelist)\n",
        "                avg_cost += loss/total_batch\n",
        "            print(\"cost =\", \"{:.3f}\".format(avg_cost))\n",
        "           # log.write(\"Average Cost: \" + str(avg_cost) + \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32uE0Co8xh6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Layer():\n",
        "\n",
        "    def __init__(self, shape, stddev, value):\n",
        "        self.weights = tf.Variable(tf.truncated_normal(shape=shape, stddev=stddev))\n",
        "        self.biases = tf.Variable(tf.constant(value=value, shape=[shape[-1]]))\n",
        "\n",
        "    def feed_forward(self, input_data, stride=None):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class Convolution_Layer(Layer):\n",
        "\n",
        "    def __init__(self, shape, stddev, value):\n",
        "        super(Convolution_Layer, self).__init__(shape, stddev, value)\n",
        "\n",
        "    def feed_forward(self, input_data, stride):\n",
        "        conv = tf.nn.conv2d(input_data, self.weights, stride, padding=\"SAME\")\n",
        "        output_data = tf.nn.tanh(tf.nn.bias_add(conv, self.biases))\n",
        "        return output_data\n",
        "\n",
        "\n",
        "class FullyConnected_Layer(Layer):\n",
        "\n",
        "    def __init__(self, shape, stddev, value):\n",
        "        super(FullyConnected_Layer, self).__init__(shape, stddev, value)\n",
        "\n",
        "    def feed_forward(self, input_data, stride=None):\n",
        "        fullyconnected = tf.matmul(input_data, self.weights)\n",
        "        output_data = tf.nn.relu(tf.nn.bias_add(fullyconnected, self.biases))\n",
        "        return output_data\n",
        "\n",
        "\n",
        "class Fusion_Layer(Convolution_Layer):\n",
        "\n",
        "    def __init__(self, shape, stddev, value):\n",
        "        super(Fusion_Layer, self).__init__(shape, stddev, value)\n",
        "\n",
        "    def feed_forward(self, mid_features, global_features, stride):\n",
        "        mid_features_shape = mid_features.get_shape().as_list()\n",
        "        mid_features_reshaped = tf.reshape(mid_features, [BATCH_SIZE, mid_features_shape[1]*mid_features_shape[2], 256])\n",
        "        fusion_level = []\n",
        "        for j in range(mid_features_reshaped.shape[0]):\n",
        "            for i in range(mid_features_reshaped.shape[1]):\n",
        "                see_mid = mid_features_reshaped[j, i, :]\n",
        "                see_mid_shape = see_mid.get_shape().as_list()\n",
        "                see_mid = tf.reshape(see_mid, [1, see_mid_shape[0]])\n",
        "                global_features_shape = global_features[j, :].get_shape().as_list()\n",
        "                see_global = tf.reshape(global_features[j, :], [1, global_features_shape[0]])\n",
        "                fusion = tf.concat([see_mid, see_global], 1)\n",
        "                fusion_level.append(fusion)\n",
        "        fusion_level = tf.stack(fusion_level, 1)\n",
        "        fusion_level = tf.reshape(fusion_level, [BATCH_SIZE, 28, 28, 512])\n",
        "        return super(Fusion_Layer, self).feed_forward(fusion_level, stride)\n",
        "\n",
        "\n",
        "class Output_Layer(Layer):\n",
        "\n",
        "    def __init__(self, shape, stddev, value):\n",
        "        super(Output_Layer, self).__init__(shape, stddev, value)\n",
        "\n",
        "    def feed_forward(self, input_data, stride):\n",
        "        conv = tf.nn.conv2d(input_data, self.weights, stride, padding='SAME')\n",
        "        output_data = tf.nn.sigmoid(tf.nn.bias_add(conv, self.biases))\n",
        "        return output_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wvm8cfsxo1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "import datetime\n",
        "\n",
        "train_data =DATA(TRAIN_DIR)\n",
        "print(\"Train Data Loaded\")\n",
        "        # BUILD MODEL\n",
        "tf.reset_default_graph()\n",
        "model =MODEL()\n",
        "print(\"Model Initialized\")\n",
        "model.build()\n",
        "print(\"Model Built\")\n",
        "        # TRAIN MODEL\n",
        "model.train(train_data)\n",
        "print(\"Model Trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRICuvHJxuZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST MODEL\n",
        "test_data =DATA(TEST_DIR)\n",
        "print(\"Test Data Loaded\")\n",
        "model.test(test_data)\n",
        "print(\"Image Reconstruction Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pquDDZg74MQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}